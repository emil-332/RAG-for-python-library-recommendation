{
  "name": "datasets",
  "summary": "HuggingFace community-driven open-source library of datasets",
  "language": "python",
  "tags": [
    "data",
    "math",
    "ml",
    "web"
  ],
  "chunks": [
    {
      "chunk_id": "datasets::chunk_0",
      "text": "Installation\n\nWith pip\n\n Datasets can be installed from PyPi and has to be installed in a virtual environment (venv or conda for instance)\n\nWith conda\n\n Datasets can be installed using conda as follows:\n\nFollow the installation pages of TensorFlow and PyTorch to see how to install them with conda.\n\nFor more details on installation, check the installation page in the documentation: https://huggingface.co/docs/datasets/installation\n\nInstallation to use with Machine Learning & Data frameworks frameworks\n\nIf you plan to use  Datasets with PyTorch (2.0+), TensorFlow (2.6+) or JAX (3.14+) you should also install PyTorch, TensorFlow or JAX.\n Datasets is also well integrated with data frameworks like PyArrow, Pandas, Polars and Spark, which should be installed separately.\n\nFor more details on using the library with these frameworks, check the quick start page in the documentation: https://huggingface.co/docs/datasets/quickstart\n\nUsage\n\n Datasets is made to be very simple to use - the API is centered around a single function, `datasets.load_dataset(dataset_name, **kwargs)`, that instantiates a dataset.\n\nThis library can be used for text/image/audio/etc. datasets. Here is an example to load a text dataset:\n\nHere is a quick example:\n\nIf your dataset is bigger than your disk or if you don't want to wait to download the data, you can use streaming:\n\nFor more details on using the library, check the quick start page in the documentation: https://huggingface.co/docs/datasets/quickstart and the specific pages on:\n\n- etc.\n\nAdd a new dataset to the Hub\n\nWe have a very detailed step-by-step guide to add a new dataset to the  datasets already provided on the [HuggingFace Datasets Hub](https://huggingface.co/datasets).\n\nYou can find:\n- [how to upload a dataset to the Hub using your web browser or Python](https://huggingface.co/docs/datasets/upload_dataset) and also\n- [how to upload it using Git](https://huggingface.co/docs/datasets/share).\n\nDisclaimers\n\nYou can use  Datasets to load datasets based on versioned git repositories maintained by the dataset authors. For reproducibility reasons, we ask users to pin the `revision` of the repositories they use.\n\nIf you're a dataset owner and wish to update any part of it (description, citation, license, etc.), or do not want your dataset to be included in the Hugging Face Hub, please get in touch by opening a discussion or a pull request in the Community tab of the dataset page. Thanks for your contribution to the ML community!\n\nBibTeX\n\nIf you want to cite our  Datasets library, you can use our [paper](https://huggingface.co/papers/2109.02846):\n\nIf you need to cite a specific version of our  Datasets library for reproducibility, you can use the corresponding version Zenodo DOI from this [list](https://zenodo.org/search?q=conceptrecid:%224817768%22&sort=-version&all_versions=True).",
      "word_count": 412
    }
  ],
  "usage_description": "This library is used to provide a unified interface for loading and managing various types of datasets in machine learning pipelines. With this library, developers can easily access and utilize a wide range of datasets from the Hugging Face community, streamlining their data preparation workflows."
}