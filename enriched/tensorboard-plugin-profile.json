{
  "name": "tensorboard-plugin-profile",
  "summary": "XProf Profiler Plugin",
  "language": "python",
  "tags": [
    "math",
    "visualization",
    "web"
  ],
  "chunks": [
    {
      "chunk_id": "tensorboard-plugin-profile::chunk_0",
      "text": "XProf (+ Tensorboard Profiler Plugin)\n\nXProf offers a number of tools to analyse and visualize the\nperformance of your model across multiple devices. Some of the tools include:\n\n*   **Overview**: A high-level overview of the performance of your model. This\n*   **Trace Viewer**: Displays a timeline of the execution of your model that shows:\n*   **Memory Profile Viewer**: Monitors the memory usage of your model.\n*   **Graph Viewer**: A visualization of the graph structure of HLOs of your model.\n\nTo learn more about the various XProf tools, check out the [XProf documentation](https://openxla.org/xprof)\n\nDemo\nFirst time user? Come and check out this [Colab Demo](https://docs.jaxstack.ai/en/latest/JAX_for_LLM_pretraining.html).\n\nQuick Start\n\nPrerequisites\n\n* xprof >= 2.20.0\n* (optional) TensorBoard >= 2.20.0\n\nNote: XProf requires access to the Internet to load the [Google Chart library](https://developers.google.com/chart/interactive/docs/basic_load_libs#basic-library-loading).\nSome charts and tables may be missing if you run XProf entirely offline on\nyour local machine, behind a corporate firewall, or in a datacenter.\n\nIf you use Google Cloud to run your workloads, we recommend the\n[xprofiler tool](https://github.com/AI-Hypercomputer/cloud-diagnostics-xprof).\nIt provides a streamlined profile collection and viewing experience using VMs\nrunning XProf.\n\nInstallation\n\nTo get the most recent release version of XProf, install it via pip:\n\nRunning XProf\n\nXProf can be launched as a standalone server or used as a plugin within\nTensorBoard. For large-scale use, it can be deployed in a distributed mode with\nseparate aggregator and worker instances ([more details on it later in the\ndoc](#distributed-profiling)).\n\nCommand-Line Arguments\n\nWhen launching XProf from the command line, you can use the following arguments:\n\n*   **`logdir`** (optional): The directory containing XProf profile data (files\n*   **`-p `**, **`--port `**: The port for the XProf web server.\n*   **`-gp `**, **`--grpc_port `**: The port for the gRPC\n*   **`-wsa `**, **`--worker_service_address `**: A\n*   **`-hcpb`**, **`--hide_capture_profile_button`**: If set, hides the 'Capture\n\nStandalone\n\nIf you have profile data in a directory (e.g., `profiler/demo`), you can view it\nby running:\n\nOr with the optional flag:\n\nWith TensorBoard\n\nIf you have TensorBoard installed, you can run:\n\nIf you are behind a corporate firewall, you may need to include the `--bind_all`\ntensorboard flag.\n\nGo to `localhost:6006/#profile` of your browser, you should now see the demo\noverview page show up.\nCongratulations! You're now ready to capture a profile.\n\nLog Directory Structure\n\nWhen using XProf, profile data must be placed in a specific directory structure.\nXProf expects `.xplane.pb` files to be in the following path:\n\n*   ``: This is the root directory that you supply to `tensorboard\n*   `plugins/profile/`: This is a required subdirectory.\n*   `/`: Each subdirectory inside `plugins/profile/` represents a\n\n**Example:**\n\nIf your log directory is structured like this:\n\nYou would launch TensorBoard with:\n\nThe runs `my_experiment_run_1` and `benchmark_20251107` will be available in the\n\"Sessions\" tab of the UI.\n\nYou can also dynamically load sessions from a GCS bucket or local filesystem by\npassing URL parameters when loading XProf in your browser. This method works\nwhether or not you provided a `logdir` at startup and is useful for viewing\nprofiles from various locations without restarting XProf.",
      "word_count": 498
    },
    {
      "chunk_id": "tensorboard-plugin-profile::chunk_1",
      "text": "For example, if you start XProf with no log directory:\n\nYou can load sessions using the following URL parameters.\n\nAssume you have profile data stored on GCS or locally, structured like this:\n\nThere are two URL parameters you can use:\n\n*   **`session_path`**: Use this to load a *single* session directly. The path\n\n*   **`run_path`**: Use this to point to a directory that contains *multiple*\n\n**Loading Precedence**\n\nIf multiple sources are provided, XProf uses the following order of precedence\nto determine which profiles to load:\n\n1.  **`session_path`** URL parameter\n2.  **`run_path`** URL parameter\n3.  **`logdir`** command-line argument\n\nDistributed Profiling\n\nXProf supports distributed profile processing by using an aggregator that\ndistributes work to multiple XProf workers. This is useful for processing large\nprofiles or handling multiple users.\n\n**Note**: Currently, distributed processing only benefits the following tools:\n`overview_page`, `framework_op_stats`, `input_pipeline`, and `pod_viewer`.\n\n**Note**: The ports used in these examples (`6006` for the aggregator HTTP\nserver, `9999` for the worker HTTP server, and `50051` for the worker gRPC\nserver) are suggestions and can be customized.\n\n**Worker Node**\n\nEach worker node should run XProf with a gRPC port exposed so it can receive\nprocessing requests. You should also hide the capture button as workers are not\nmeant to be interacted with directly.\n\n**Aggregator Node**\n\nThe aggregator node runs XProf with the `--worker_service_address` flag pointing\nto all available workers. Users will interact with aggregator node's UI.\n\nReplace `, ` with the addresses of your worker machines.\nRequests sent to the aggregator on port 6006 will be distributed among the\nworkers for processing.\n\nFor deploying a distributed XProf setup in a Kubernetes environment, see\n[Kubernetes Deployment Guide](docs/kubernetes_deployment.md).\n\nNightlies\n\nEvery night, a nightly version of the package is released under the name of\n`xprof-nightly`. This package contains the latest changes made by the XProf\ndevelopers.\n\nTo install the nightly version of profiler:\n\nNext Steps\n\n* [JAX Profiling Guide](https://jax.readthedocs.io/en/latest/profiling.html#xprof-tensorboard-profiling)\n* [PyTorch/XLA Profiling Guide](https://cloud.google.com/tpu/docs/pytorch-xla-performance-profiling-tpu-vm)\n* [TensorFlow Profiling Guide](https://tensorflow.org/guide/profiler)\n* [Cloud TPU Profiling Guide](https://cloud.google.com/tpu/docs/cloud-tpu-tools)\n* [Colab Tutorial](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras)\n* [Tensorflow Colab](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras)",
      "word_count": 329
    }
  ],
  "usage_description": "This library is used to analyze and visualize the performance of a model across multiple devices, providing tools such as an overview, trace viewer, memory profile viewer, and graph viewer. Developers can use this library with XProf and Tensorboard to gain insights into their model's execution timeline, memory usage, and graph structure."
}