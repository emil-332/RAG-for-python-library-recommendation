{
  "name": "hdbscan",
  "summary": "Clustering based on density with variable density clusters",
  "language": "python",
  "tags": [
    "math",
    "visualization",
    "web"
  ],
  "chunks": [
    {
      "chunk_id": "hdbscan::chunk_0",
      "text": ".. image:: https://img.shields.io/pypi/v/hdbscan.svg\n\n.. image:: https://img.shields.io/pypi/l/hdbscan.svg\n.. image:: https://travis-ci.org/scikit-learn-contrib/hdbscan.svg\n\n:target: https://codecov.io/gh/scikit-learn-contrib/hdbscan\n\n.. image:: http://joss.theoj.org/papers/10.21105/joss.00205/status.svg\n\n=======\nHDBSCAN\n=======\n\nHDBSCAN - Hierarchical Density-Based Spatial Clustering of Applications\nwith Noise. Performs DBSCAN over varying epsilon values and integrates \nthe result to find a clustering that gives the best stability over epsilon.\nThis allows HDBSCAN to find clusters of varying densities (unlike DBSCAN),\nand be more robust to parameter selection.\n\nIn practice this means that HDBSCAN returns a good clustering straight\naway with little or no parameter tuning -- and the primary parameter,\nminimum cluster size, is intuitive and easy to select.\n\nHDBSCAN is ideal for exploratory data analysis; it's a fast and robust\nalgorithm that you can trust to return meaningful clusters (if there\nare any).\n\nBased on the papers:\n\nDocumentation, including tutorials, are available on ReadTheDocs at http://hdbscan.readthedocs.io/en/latest/ .  \nNotebooks `comparing HDBSCAN to other clustering algorithms `_, explaining `how HDBSCAN works `_ and `comparing performance with other python clustering implementations `_ are available.\n\n------------------\nHow to use HDBSCAN\n------------------\n\nThe hdbscan package inherits from sklearn classes, and thus drops in neatly\nnext to other sklearn clusterers with an identical calling API. Similarly it\nsupports input in a variety of formats: an array (or pandas dataframe, or\nsparse matrix) of shape ``(num_samples x num_features)``; an array (or sparse matrix)\ngiving a distance matrix between samples.\n\n.. code:: python\n\n-----------\nPerformance\n-----------\n\nSignificant effort has been put into making the hdbscan implementation as fast as \npossible. It is `orders of magnitude faster than the reference implementation `_ in Java,\nand is currently faster than highly optimized single linkage implementations in C and C++.\n`version 0.7 performance can be seen in this notebook `_ .\nIn particular `performance on low dimensional data is better than sklearn's DBSCAN `_ ,\nand via support for caching with joblib, re-clustering with different parameters\ncan be almost free.\n\n------------------------\nAdditional functionality\n------------------------\n\nThe hdbscan package comes equipped with visualization tools to help you\nunderstand your clustering results. After fitting data the clusterer\nobject has attributes for:\n\n* The condensed cluster hierarchy\n* The robust single linkage cluster hierarchy\n* The reachability distance minimal spanning tree\n\nAll of which come equipped with methods for plotting and converting\nto Pandas or NetworkX for further analysis. See the notebook on\n`how HDBSCAN works `_ for examples and further details.\n\nThe clusterer objects also have an attribute providing cluster membership\nstrengths, resulting in optional soft clustering (and no further compute \nexpense). Finally each cluster also receives a persistence score giving\nthe stability of the cluster over the range of distance scales present\nin the data. This provides a measure of the relative strength of clusters.\n\n-----------------\nOutlier Detection\n-----------------",
      "word_count": 446
    },
    {
      "chunk_id": "hdbscan::chunk_1",
      "text": "The HDBSCAN clusterer objects also support the GLOSH outlier detection algorithm. \nAfter fitting the clusterer to data the outlier scores can be accessed via the\n``outlier_scores_`` attribute. The result is a vector of score values, one for\neach data point that was fit. Higher scores represent more outlier like objects.\nSelecting outliers via upper quantiles is often a good approach.\n\nBased on the paper:\n\n---------------------\nRobust single linkage\n---------------------\n\nThe hdbscan package also provides support for the *robust single linkage*\nclustering algorithm of Chaudhuri and Dasgupta. As with the HDBSCAN \nimplementation this is a high performance version of the algorithm \noutperforming scipy's standard single linkage implementation. The\nrobust single linkage hierarchy is available as an attribute of\nthe robust single linkage clusterer, again with the ability to plot\nor export the hierarchy, and to extract flat clusterings at a given\ncut level and gamma value.\n\nExample usage:\n\n.. code:: python\n\nBased on the paper:\n\n----------------\nBranch detection\n----------------\n\nThe hdbscan package supports a branch-detection post-processing step \nby `Bot et al. `_. Cluster shapes,\nsuch as branching structures, can reveal interesting patterns \nthat are not expressed in density-based cluster hierarchies. The \nBranchDetector class mimics the HDBSCAN API and can be used to\ndetect branching hierarchies in clusters. It provides condensed \nbranch hierarchies, branch persistences, and branch memberships and \nsupports joblib's caching functionality. A notebook \n`demonstrating the BranchDetector is available `_.\n\nExample usage:\n\n.. code:: python\n\nBased on the paper:\n\n----------\nInstalling\n----------\n\nEasiest install, if you have Anaconda (thanks to conda-forge which is awesome!):\n\n.. code:: bash\n\nPyPI install, presuming you have an up to date pip:\n\n.. code:: bash\n\nBinary wheels for a number of platforms are available thanks to the work of\nRyan Helinski .\n\nIf pip is having difficulties pulling the dependencies then we'd suggest to first upgrade\npip to at least version 10 and try again:\n\n.. code:: bash\n\nOtherwise install the dependencies manually using anaconda followed by pulling hdbscan from pip:\n\n.. code:: bash\n\nFor a manual install of the latest code directly from GitHub:\n\n.. code:: bash\n\nAlternatively download the package, install requirements, and manually run the installer:\n\n.. code:: bash\n\n-----------------\nRunning the Tests\n-----------------\n\nThe package tests can be run after installation using the command:\n\n.. code:: bash\n\nor, if ``nose`` is installed but ``nosetests`` is not in your ``PATH`` variable:\n\n.. code:: bash\n\nIf one or more of the tests fail, please report a bug at https://github.com/scikit-learn-contrib/hdbscan/issues/new\n\n--------------\nPython Version\n--------------\n\nThe hdbscan library supports both Python 2 and Python 3. However we recommend Python 3 as the better option if it is available to you.\n----------------\nHelp and Support\n----------------\n\nFor simple issues you can consult the `FAQ `_ in the documentation.\nIf your issue is not suitably resolved there, please check the `issues `_ on github. Finally, if no solution is available there feel free to `open an issue `_ ; the authors will attempt to respond in a reasonably timely fashion.\n\n------------\nContributing\n------------",
      "word_count": 495
    },
    {
      "chunk_id": "hdbscan::chunk_2",
      "text": "We welcome contributions in any form! Assistance with documentation, particularly expanding tutorials,\nis always welcome. To contribute please `fork the project `_ make your changes and submit a pull request. We will do our best to work through any issues with\nyou and get your code merged into the main branch.\n\n------\nCiting\n------\n\nIf you have used this codebase in a scientific publication and wish to cite it, please use the `Journal of Open Source Software article `_.\n\n.. code:: bibtex\n\nTo reference the high performance algorithm developed in this library please cite our paper in ICDMW 2017 proceedings.\n\n.. code:: bibtex\n\nIf you used the branch-detection functionality in this library please cite our `PeerJ paper `_:\n\n.. code:: bibtex\n\n---------\nLicensing\n---------\n\nThe hdbscan package is 3-clause BSD licensed. Enjoy.",
      "word_count": 132
    }
  ]
}