{
  "name": "numdifftools",
  "summary": "Solves automatic numerical differentiation problems in one or more variables.",
  "language": "python",
  "tags": [
    "math",
    "web"
  ],
  "chunks": [
    {
      "chunk_id": "numdifftools::chunk_0",
      "text": "============\nnumdifftools\n============\n\nThe numdifftools library is a suite of tools written in `_Python `_\nto solve automatic numerical differentiation problems in one or more variables.\nFinite differences are used in an adaptive manner, coupled with a Richardson\nextrapolation methodology to provide a maximally accurate result.\nThe user can configure many options like; changing the order of the method or\nthe extrapolation, even allowing the user to specify whether complex-step,\ncentral, forward or backward differences are used.\n\nThe methods provided are:\n\n- **Derivative**: Compute the derivatives of order 1 through 10 on any scalar function.\n\n- **directionaldiff**: Compute directional derivative of a function of n variables\n\n- **Gradient**: Compute the gradient vector of a scalar function of one or more variables.\n\n- **Jacobian**: Compute the Jacobian matrix of a vector valued function of one or more variables.\n\n- **Hessian**: Compute the Hessian matrix of all 2nd partial derivatives of a scalar function of one or more variables.\n\n- **Hessdiag**: Compute only the diagonal elements of the Hessian matrix\n\nAll of these methods also produce error estimates on the result.\n\nNumdifftools also provide an easy to use interface to derivatives calculated\nwith in `_AlgoPy `_. Algopy stands for Algorithmic\nDifferentiation in Python.\nThe purpose of AlgoPy is the evaluation of higher-order derivatives in the\n`forward` and `reverse` mode of Algorithmic Differentiation (AD) of functions\nthat are implemented as Python programs.\n\nGetting Started\n===============\n\nVisualize high order derivatives of the tanh function\n\n.. image:: https://raw.githubusercontent.com/pbrod/numdifftools/master/examples/fun.png\n\nCompute 1'st and 2'nd derivative of exp(x), at x == 1::\n\nNonlinear least squares::\n\nCompute gradient of sum(x**2)::\n\nCompute the same with the easy to use interface to AlgoPy::\n\nNonlinear least squares::\n\nCompute gradient of sum(x**2)::\n\nSee also\n--------\nscipy.misc.derivative\n\nDocumentation and code\n======================\n\nNumdifftools works on Python 2.7+ and Python 3.0+.\n\nOfficial releases available at: http://pypi.python.org/pypi/numdifftools |pkg_img|\n\nOfficial documentation available at: http://numdifftools.readthedocs.io/en/latest/ |docs_img|\n\nBleeding edge: https://github.com/pbrod/numdifftools.\n\nInstallation\n============\n\nIf you have pip installed, then simply type:\n\nto get the lastest stable version. Using pip also has the advantage that all\nrequirements are automatically installed.\n\nUnit tests\n==========\nTo test if the toolbox is working paste the following in an interactive\npython session::\n\n   import numdifftools as nd\n   nd.test('--doctest-modules', '--disable-warnings')\n\nAcknowledgement\n===============\nThe `numdifftools package `_ for\n`Python `_ was written by Per A. Brodtkorb\nbased on the adaptive numerical differentiation toolbox written in\n`Matlab `_  by John D'Errico [DErrico06]_.\n\nLater the package was extended with some of the functionality\nfound in the statsmodels.tools.numdiff module written by Josef Perktold\n[JPerktold14]_ which is based on [Rid09]_.\nThe implementation of bicomplex numbers is based on the matlab implementation\ndescribed in the project report of [Ver14]_ which is based on [GLD12].\nFor completeness the [For98]_  method for computing the weights and points in general\nfinite difference formulas as well as the [For81]_ method for cumputing the\ntaylor coefficients of complex analytic function using FFT, was added.\n\nReferences\n===========\n\n.. [JPerktold14] Perktold, J (2014), numdiff package\n\n.. [Ver14] Adriaen Verheyleweghen, (2014)\n\n.. [GLD12] Gregory Lantoine, R.P. Russell, and T. Dargent (2012)\n\n.. [MELEV12] M.E. Luna-Elizarraras, M. Shapiro, D.C. Struppa1, A. Vajiac (2012),\n\n.. [Lan10] Gregory Lantoine (2010),\n\n.. [Rid09] Ridout, M.S. (2009)\n\n.. [DErrico06] D'Errico, J. R.  (2006),\n\n.. [KLLK05] K.-L. Lai, J.L. Crassidis, Y. Cheng, J. Kim (2005),\n\n.. [For98] B. Fornberg (1998)\n\n.. [For81] Fornberg, B. (1981).\n\n.. [JML69] Lyness, J. M., Moler, C. B. (1969).\n\n.. [JML66] Lyness, J. M., Moler, C. B. (1966).\n\n.. [NAG] *NAG Library*. NAG Fortran Library Document: D04AAF",
      "word_count": 574
    }
  ],
  "usage_description": "Here is a 2-sentence summary of what a developer can achieve with this library:\n\nThis library is used to automatically and accurately compute derivatives, gradients, and directional derivatives of functions in one or more variables using various numerical differentiation methods. By leveraging numdifftools, developers can easily and efficiently calculate the derivative of any scalar function with respect to its inputs, enabling tasks such as optimization and sensitivity analysis."
}