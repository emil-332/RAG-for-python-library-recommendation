{
  "name": "torchaudio",
  "summary": "An audio package for PyTorch",
  "language": "python",
  "tags": [
    "data",
    "math",
    "ml",
    "ui",
    "web"
  ],
  "chunks": [
    {
      "chunk_id": "torchaudio::chunk_0",
      "text": "torchaudio: an audio library for PyTorch\n========================================\n\n(https://pytorch.org/audio/main/)\n(https://anaconda.org/pytorch/torchaudio)\n(https://anaconda.org/pytorch/torchaudio)\n\n> [!NOTE]\n> **We have transitioned TorchAudio into a\n>  maintenance phase. This process removed some user-facing\n>  features. These features were deprecated from TorchAudio 2.8 and removed in 2.9.\n>  Our main goals were to reduce redundancies with the rest of the\n>  PyTorch ecosystem, make it easier to maintain, and create a version of\n>  TorchAudio that is more tightly scoped to its strengths: processing audio\n>  data for ML. Please see\n>  [our community message](https://github.com/pytorch/audio/issues/3902)\n>  for more details.**\n\nThe aim of torchaudio is to apply [PyTorch](https://github.com/pytorch/pytorch) to\nthe audio domain. By supporting PyTorch, torchaudio follows the same philosophy\nof providing strong GPU acceleration, having a focus on trainable features through\nthe autograd system, and having consistent style (tensor names and dimension names).\nTherefore, it is primarily a machine learning library and not a general signal\nprocessing library. The benefits of PyTorch can be seen in torchaudio through\nhaving all the computations be through PyTorch operations which makes it easy\nto use and feel like a natural extension.\n\n- [Dataloaders for common audio datasets](http://pytorch.org/audio/main/datasets.html)\n- Audio and speech processing functions\n  - [forced_align](https://pytorch.org/audio/main/generated/torchaudio.functional.forced_align.html)\n- Common audio transforms\n  - [Spectrogram, AmplitudeToDB, MelScale, MelSpectrogram, MFCC, MuLawEncoding, MuLawDecoding, Resample](http://pytorch.org/audio/main/transforms.html)\n- Compliance interfaces: Run code using PyTorch that align with other libraries\n  - [Kaldi: spectrogram, fbank, mfcc](https://pytorch.org/audio/main/compliance.kaldi.html)\n\nInstallation\n------------\n\nPlease refer to https://pytorch.org/audio/main/installation.html for installation and build process of TorchAudio.\n\nAPI Reference\n-------------\n\nAPI Reference is located here: http://pytorch.org/audio/main/\n\nContributing Guidelines\n-----------------------\n\nPlease refer to [CONTRIBUTING.md](./CONTRIBUTING.md)\n\nCitation\n--------\n\nIf you find this package useful, please cite as:\n\nDisclaimer on Datasets\n----------------------\n\nThis is a utility library that downloads and prepares public datasets. We do not host or distribute these datasets, vouch for their quality or fairness, or claim that you have license to use the dataset. It is your responsibility to determine whether you have permission to use the dataset under the dataset's license.\n\nIf you're a dataset owner and wish to update any part of it (description, citation, etc.), or do not want your dataset to be included in this library, please get in touch through a GitHub issue. Thanks for your contribution to the ML community!\n\nPre-trained Model License\n-------------------------\n\nThe pre-trained models provided in this library may have their own licenses or terms and conditions derived from the dataset used for training. It is your responsibility to determine whether you have permission to use the models for your use case.\n\nFor instance, SquimSubjective model is released under the Creative Commons Attribution Non Commercial 4.0 International (CC-BY-NC 4.0) license. See [the link](https://zenodo.org/record/4660670#.ZBtWPOxuerN) for additional details.\n\nOther pre-trained models that have different license are noted in documentation. Please checkout the [documentation page](https://pytorch.org/audio/main/).",
      "word_count": 451
    }
  ],
  "usage_description": "Here is a 2-sentence summary of what a developer can achieve with the Torchaudio library:\n\nThis library is used to process audio data for machine learning tasks within the PyTorch ecosystem, allowing developers to efficiently load, manipulate, and prepare audio datasets for training and inference. By leveraging Torchaudio's capabilities, developers can build and fine-tune models that excel at audio-related tasks such as speech recognition, music classification, and more."
}