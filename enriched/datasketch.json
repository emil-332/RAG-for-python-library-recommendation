{
  "name": "datasketch",
  "summary": "Probabilistic data structures for processing and searching very large datasets",
  "language": "python",
  "tags": [
    "data",
    "math",
    "web"
  ],
  "chunks": [
    {
      "chunk_id": "datasketch::chunk_0",
      "text": "datasketch: Big Data Looks Small\n================================\n\n   :target: https://zenodo.org/doi/10.5281/zenodo.598238\n\ndatasketch gives you probabilistic data structures that can process and\nsearch very large amount of data super fast, with little loss of\naccuracy.\n\nThis package contains the following data sketches:\n\n+-------------------------+-----------------------------------------------+\nData Sketch\n+=========================+===============================================+\n`MinHash`_\n+-------------------------+-----------------------------------------------+\n`Weighted MinHash`_\n+-------------------------+-----------------------------------------------+\n`HyperLogLog`_\n+-------------------------+-----------------------------------------------+\n`HyperLogLog++`_\n+-------------------------+-----------------------------------------------+\n\nThe following indexes for data sketches are provided to support\nsub-linear query time:\n\n+---------------------------+-----------------------------+------------------------+\nIndex\n+===========================+=============================+========================+\n`MinHash LSH`_\n+---------------------------+-----------------------------+------------------------+\n`LSHBloom`_\n+---------------------------+-----------------------------+------------------------+\n`MinHash LSH Forest`_\n+---------------------------+-----------------------------+------------------------+\n`MinHash LSH Ensemble`_\n+---------------------------+-----------------------------+------------------------+\n`HNSW`_\n+---------------------------+-----------------------------+------------------------+\n\ndatasketch must be used with Python 3.9 or above, NumPy 1.11 or above, and Scipy.\n\nNote that `MinHash LSH`_ and `MinHash LSH Ensemble`_ also support Redis and Cassandra \nstorage layer (see `MinHash LSH at Scale`_).\n\nInstall\n-------\n\nTo install datasketch using ``pip``:\n\n.. code-block:: bash\n\nThis will also install NumPy as dependency.\n\nTo install with Redis dependency:\n\n.. code-block:: bash\n\nTo install with Cassandra dependency:\n\n.. code-block:: bash\n\nTo install with Bloom filter dependency:\n\n.. code-block:: bash\n\n.. _`MinHash`: https://ekzhu.github.io/datasketch/minhash.html\n.. _`Weighted MinHash`: https://ekzhu.github.io/datasketch/weightedminhash.html\n.. _`HyperLogLog`: https://ekzhu.github.io/datasketch/hyperloglog.html\n.. _`HyperLogLog++`: https://ekzhu.github.io/datasketch/hyperloglog.html#hyperloglog-plusplus\n.. _`MinHash LSH`: https://ekzhu.github.io/datasketch/lsh.html\n.. _`MinHash LSH Forest`: https://ekzhu.github.io/datasketch/lshforest.html\n.. _`MinHash LSH Ensemble`: https://ekzhu.github.io/datasketch/lshensemble.html\n.. _`LSHBloom`: https://ekzhu.github.io/datasketch/lshbloom.html\n.. _`Minhash LSH at Scale`: http://ekzhu.github.io/datasketch/lsh.html#minhash-lsh-at-scale\n.. _`HNSW`: https://ekzhu.github.io/datasketch/documentation.html#hnsw\n\nContributing\n------------\n\nWe welcome contributions from everyone. Whether you're fixing bugs, adding features, improving documentation, or helping with tests, your contributions are valuable.\n\nDevelopment Setup\n^^^^^^^^^^^^^^^^^\n\nThe project uses `uv` for fast and reliable Python package management. Follow these steps to set up your development environment:\n\n1. **Install uv**: Follow the official installation guide at https://docs.astral.sh/uv/getting-started/installation/\n\n2. **Clone the repository**:\n\n   .. code-block:: bash\n\n3. **Set up the environment**:\n\n   .. code-block:: bash\n\n4. **Verify installation**:\n\n   .. code-block:: bash\n\n5. **Optional dependencies** (for specific development needs):\n\n   .. code-block:: bash\n\nLearn more about `uv` at https://docs.astral.sh/uv/\n\nDevelopment Workflow\n^^^^^^^^^^^^^^^^^^^^\n\n1. **Fork the repository** on GitHub if you haven't already.\n\n2. **Create a feature branch** for your changes:\n\n   .. code-block:: bash\n\n3. **Make your changes** following the project's coding standards.\n\n4. **Run the tests** to ensure nothing is broken:\n\n   .. code-block:: bash\n\n5. **Check code quality** with ruff:\n\n   .. code-block:: bash\n\n6. **Commit your changes** with a clear, descriptive commit message:\n\n   .. code-block:: bash\n\n7. **Push to your fork** and create a pull request on GitHub:\n\n   .. code-block:: bash\n\n8. **Respond to feedback** from maintainers and iterate on your changes.\n\nGuidelines\n^^^^^^^^^^\n\n- Follow PEP 8 style guidelines\n- Write tests for new features\n- Update documentation as needed\n- Keep commits focused and atomic\n- Be respectful in discussions\n\nFor more information, check the `GitHub issues `_ for current priorities or areas needing help. You can also join the discussion on `project roadmap and priorities `_.",
      "word_count": 441
    }
  ],
  "usage_description": "Here is a 2-sentence summary of what a developer can achieve with the datasketch library:\n\nThis library is used to efficiently process and search very large datasets while maintaining high accuracy, making it ideal for big data applications. With datasketch, developers can rapidly identify patterns and similarities in massive datasets using probabilistic data structures like MinHash, Weighted MinHash, HyperLogLog, and HyperLogLog++."
}