{
  "name": "optype",
  "summary": "Building Blocks for Precise & Flexible Type Hints",
  "language": "python",
  "tags": [
    "data",
    "math",
    "ui",
    "web"
  ],
  "chunks": [
    {
      "chunk_id": "optype::chunk_0",
      "text": "Installation\n\nPyPI\n\nOptype is available as [`optype`][PYPI] on PyPI:\n\nFor optional [NumPy][NUMPY] support, ensure that you use the `optype[numpy]` extra.\nThis ensures that the installed `numpy` and the required [`numpy-typing-compat`][NPTC]\nversions are compatible with each other.\n\nSee the [`optype.numpy` docs](#optypenumpy) for more info.\n\nConda\n\nOptype can also be installed with `conda` from the [`conda-forge`][CONDA] channel:\n\nIf you want to use [`optype.numpy`](#optypenumpy), you should instead install\n[`optype-numpy`][CONDA-NP]:\n\nExample\n\nLet's say you're writing a `twice(x)` function, that evaluates `2 * x`.\nImplementing it is trivial, but what about the type annotations?\n\nBecause `twice(2) == 4`, `twice(3.14) == 6.28` and `twice('I') = 'II'`, it\nmight seem like a good idea to type it as `twice[T](x: T) -> T: ...`.\nHowever, that wouldn't include cases such as `twice(True) == 2` or\n`twice((42, True)) == (42, True, 42, True)`, where the input- and output types\ndiffer.\nMoreover, `twice` should accept *any* type with a custom `__rmul__` method\nthat accepts `2` as argument.\n\nThis is where `optype` comes in handy, which has single-method protocols for\n*all* the builtin special methods.\nFor `twice`, we can use `optype.CanRMul[T, R]`, which, as the name suggests,\nis a protocol with (only) the `def __rmul__(self, lhs: T) -> R: ...` method.\nWith this, the `twice` function can written as:\n\nPython 3.11\nPython 3.12+\n\nBut what about types that implement `__add__` but not `__radd__`?\nIn this case, we could return `x * 2` as fallback (assuming commutativity).\nBecause the `optype.Can*` protocols are runtime-checkable, the revised\n`twice2` function can be compactly written as:\n\nPython 3.11\nPython 3.12+\n\nSee [`examples/twice.py`](examples/twice.py) for the full example.\n\nReference\n\nThe API of `optype` is flat; a single `import optype as opt` is all you need\n(except for `optype.numpy`).\n\n- [`optype`](#optype)\n  - [`Just`](#just)\n  - [Builtin type conversion](#builtin-type-conversion)\n  - [Rich relations](#rich-relations)\n  - [Binary operations](#binary-operations)\n  - [Reflected operations](#reflected-operations)\n  - [Inplace operations](#inplace-operations)\n  - [Unary operations](#unary-operations)\n  - [Rounding](#rounding)\n  - [Callables](#callables)\n  - [Iteration](#iteration)\n  - [Awaitables](#awaitables)\n  - [Async Iteration](#async-iteration)\n  - [Containers](#containers)\n  - [Attributes](#attributes)\n  - [Context managers](#context-managers)\n  - [Descriptors](#descriptors)\n  - [Buffer types](#buffer-types)\n- [`optype.copy`](#optypecopy)\n- [`optype.dataclasses`](#optypedataclasses)\n- [`optype.inspect`](#optypeinspect)\n- [`optype.io`](#optypeio)\n- [`optype.json`](#optypejson)\n- [`optype.pickle`](#optypepickle)\n- [`optype.string`](#optypestring)\n- [`optype.typing`](#optypetyping)\n  - [`Any*` type aliases](#any-type-aliases)\n  - [`Empty*` type aliases](#empty-type-aliases)\n  - [Literal types](#literal-types)\n- [`optype.dlpack`](#optypedlpack)\n- [`optype.numpy`](#optypenumpy)\n  - [Shape-typing](#shape-typing)\n  - [Array-likes](#array-likes)\n  - [Literals](#literals)\n  - [`compat` submodule](#compat-submodule)\n  - [`random` submodule](#random-submodule)\n  - [`Any*Array` and `Any*DType`](#anyarray-and-anydtype)\n  - [Low-level interfaces](#low-level-interfaces)\n\n`optype`\n\nThere are five flavors of things that live within `optype`,",
      "word_count": 387
    },
    {
      "chunk_id": "optype::chunk_1",
      "text": "- The `optype.Just[T]` and its `optype.Just{Int,Float,Complex}` subtypes only accept\n  instances of the type itself, while rejecting instances of strict subtypes.\n  This can be used to e.g. work around the `float` and `complex`\n  [type promotions][BAD], annotating `object()` sentinels with `Just[object]`,\n  rejecting `bool` in functions that accept `int`, etc.\n- `optype.Can{}` types describe *what can be done* with it.\n  For instance, any `CanAbs[T]` type can be used as argument to the `abs()`\n  builtin function with return type `T`. Most `Can{}` implement a single\n  special method, whose name directly matches that of the type. `CanAbs`\n  implements `__abs__`, `CanAdd` implements `__add__`, etc.\n- `optype.Has{}` is the analogue of `Can{}`, but for special *attributes*.\n  `HasName` has a `__name__` attribute, `HasDict` has a `__dict__`, etc.\n- `optype.Does{}` describe the *type of operators*.\n  So `DoesAbs` is the type of the `abs({})` builtin function,\n  and `DoesPos` the type of the `+{}` prefix operator.\n- `optype.do_{}` are the correctly-typed implementations of `Does{}`. For\n  each `do_{}` there is a `Does{}`, and vice-versa.\n  So `do_abs: DoesAbs` is the typed alias of `abs({})`,\n  and `do_pos: DoesPos` is a typed version of `operator.pos`.\n  The `optype.do_` operators are more complete than `operators`,\n  have runtime-accessible type annotations, and have names you don't\n  need to know by heart.\n\nThe reference docs are structured as follows:\n\nAll [typing protocols][PC] here live in the root `optype` namespace.\nThey are [runtime-checkable][RC] so that you can do e.g.\n`isinstance('snail', optype.CanAdd)`, in case you want to check whether\n`snail` implements `__add__`.\n\nUnlike`collections.abc`, `optype`'s protocols aren't abstract base classes,\ni.e. they don't extend `abc.ABC`, only `typing.Protocol`.\nThis allows the `optype` protocols to be used as building blocks for `.pyi`\ntype stubs.\n\n`Just`\n\n`Just` is an invariant type \"wrapper\", where `Just[T]` only accepts instances of `T`,\nand rejects instances of any strict subtypes of `T`.\n\nNote that e.g. `Literal[\"\"]` and `LiteralString` are not a strict `str` subtypes,\nand are therefore assignable to `Just[str]`, but instances of `class S(str): ...`\nare **not** assignable to `Just[str]`.\n\nDisallow passing `bool` as `int`:\n\nAnnotating a sentinel:\n\n> [!TIP]\n> The `Just{Bytes,Int,Float,Complex,Date,Object}` protocols are runtime-checkable,\n> so that `instance(42, JustInt) is True` and `instance(bool(), JustInt) is False`.\n> It's implemented through meta-classes, and type-checkers have no problem with it.\n\n`optype` type\n-------------\n`Just[T]`\n`JustInt`\n`JustFloat`\n`JustComplex`\n`JustBytes`\n`JustObject`\n`JustDate`\n\nBuiltin type conversion\n\nThe return type of these special methods is *invariant*. Python will raise an\nerror if some other (sub)type is returned.\nThis is why these `optype` interfaces don't accept generic type arguments.\n\nRich relations\n\nThe \"rich\" comparison special methods often return a `bool`.\nHowever, instances of any type can be returned (e.g. a numpy array).\nThis is why the corresponding `optype.Can*` interfaces accept a second type\nargument for the return type, that defaults to `bool` when omitted.\nThe first type parameter matches the passed method argument, i.e. the\nright-hand side operand, denoted here as `x`.\n\nBinary operations",
      "word_count": 470
    },
    {
      "chunk_id": "optype::chunk_2",
      "text": "In the [Python docs][NT], these are referred to as \"arithmetic operations\".\nBut the operands aren't limited to numeric types, and because the\noperations aren't required to be commutative, might be non-deterministic, and\ncould have side-effects.\nClassifying them \"arithmetic\" is, at the very least, a bit of a stretch.\n\n> [!TIP]\n> Because `pow()` can take an optional third argument, `optype`\n> provides separate interfaces for `pow()` with two and three arguments.\n> Additionally, there is the overloaded intersection type\n> `type CanPow[-T, -M, +R, +RM] = CanPow2[T, R] & CanPow3[T, M, RM]`, as interface\n> for types that can take an optional third argument.\n\n> [!NOTE]\n> The `Can*Self` protocols method return `typing.Self` and optionally accept `T` and\n> `R`. The `Can*Same` protocols also return `Self`, but instead accept `Self | T`, with\n> `T` and `R` optional generic type parameters that default to `typing.Never`.\n> To illustrate, `CanAddSelf[T]` implements `__add__` as `(self, rhs: T, /) -> Self`,\n> while `CanAddSame[T, R]` implements it as `(self, rhs: Self | T, /) -> Self | R`, and\n> `CanAddSame` (without `T` and `R`) as `(self, rhs: Self, /) -> Self`.\n\nReflected operations\n\nFor the binary infix operators above, `optype` additionally provides\ninterfaces with *reflected* (swapped) operands, e.g. `__radd__` is a reflected\n`__add__`.\nThey are named like the original, but prefixed with `CanR` prefix, i.e.\n`__name__.replace('Can', 'CanR')`.\n\n> [!NOTE]\n> `CanRPow` corresponds to `CanPow2`; the 3-parameter \"modulo\" `pow` does not\n> reflect in Python.\n>\n> According to the relevant [python docs][RPOW]:\n>\n>> Note that ternary `pow()` will not try calling `__rpow__()` (the coercion\n>> rules would become too complicated).\n\nInplace operations\n\nSimilar to the reflected ops, the inplace/augmented ops are prefixed with\n`CanI`, namely:\n\nThese inplace operators usually return themselves (after some in-place mutation).\nBut unfortunately, it currently isn't possible to use `Self` for this (i.e.\nsomething like `type MyAlias[T] = optype.CanIAdd[T, Self]` isn't allowed).\nSo to help ease this unbearable pain, `optype` comes equipped with ready-made\naliases for you to use. They bear the same name, with an additional `*Self`\nsuffix, e.g. `optype.CanIAddSelf[T]`.\n\n> [!NOTE]\n> The `CanI*Self` protocols method return `typing.Self` and optionally accept `T`. The\n> `CanI*Same` protocols also return `Self`, but instead accept `rhs: Self | T`. Since\n> `T` defaults to `Never`, it will accept `rhs: Self | Never` if `T` is not provided,\n> which is equivalent to `rhs: Self`.\n>\n> *Available since `0.12.1`*\n\nUnary operations\n\nThe `Can*Self` variants return `-> Self` instead of `R`. Since optype 0.12.1 these\nalso accept an optional `R` type parameter (with a default of `Never`), which, when\nprovided, will result in a return type of `-> Self | R`.\n\nRounding\n\nThe `round()` built-in function takes an optional second argument.\nFrom a typing perspective, `round()` has two overloads, one with 1 parameter,\nand one with two.\nFor both overloads, `optype` provides separate operand interfaces:\n`CanRound1[R]` and `CanRound2[T, RT]`.\nAdditionally, `optype` also provides their (overloaded) intersection type:\n`CanRound[-T, +R1, +R2] = CanRound1[R1] & CanRound2[T, R2]`.",
      "word_count": 496
    },
    {
      "chunk_id": "optype::chunk_3",
      "text": "For example, type-checkers will mark the following code as valid (tested with\npyright in strict mode):\n\nFurthermore, there are the alternative rounding functions from the\n[`math`][MATH] standard library:\n\nAlmost all implementations use `int` for `R`.\nIn fact, if no type for `R` is specified, it will default in `int`.\nBut technically speaking, these methods can be made to return anything.\n\nCallables\n\nUnlike `operator`, `optype` provides an operator for callable objects:\n`optype.do_call(f, *args. **kwargs)`.\n\n`CanCall` is similar to `collections.abc.Callable`, but is runtime-checkable,\nand doesn't use esoteric hacks.\n\n> [!NOTE]\n> Pyright (and probably other typecheckers) tend to accept\n> `collections.abc.Callable` in more places than `optype.CanCall`.\n> This could be related to the lack of co/contra-variance specification for\n> `typing.ParamSpec` (they should almost always be contravariant, but\n> currently they can only be invariant).\n>\n> In case you encounter such a situation, please open an issue about it, so we\n> can investigate further.\n\nIteration\n\nThe operand `x` of `iter(_)` is within Python known as an *iterable*, which is\nwhat `collections.abc.Iterable[V]` is often used for (e.g. as base class, or\nfor instance checking).\n\nThe `optype` analogue is `CanIter[R]`, which as the name suggests,\nalso implements `__iter__`. But unlike `Iterable[V]`, its type parameter `R`\nbinds to the return type of `iter(_) -> R`. This makes it possible to annotate\nthe specific type of the *iterable* that `iter(_)` returns. `Iterable[V]` is\nonly able to annotate the type of the iterated value. To see why that isn't\npossible, see [python/typing#548](https://github.com/python/typing/issues/548).\n\nThe `collections.abc.Iterator[V]` is even more awkward; it is a subtype of\n`Iterable[V]`. For those familiar with `collections.abc` this might come as a\nsurprise, but an iterator only needs to implement `__next__`, `__iter__` isn't\nneeded. This means that the `Iterator[V]` is unnecessarily restrictive.\nApart from that being theoretically \"ugly\", it has significant performance\nimplications, because the time-complexity of `isinstance` on a\n`typing.Protocol` is $O(n)$, with the $n$ referring to the amount of members.\nSo even if the overhead of the inheritance and the `abc.ABC` usage is ignored,\n`collections.abc.Iterator` is twice as slow as it needs to be.\n\nThat's one of the (many) reasons that `optype.CanNext[V]` and\n`optype.CanIter[R]` are the better alternatives to `Iterable` and `Iterator`\nfrom the abracadabra collections. This is how they are defined:\n\nFor the sake of compatibility with `collections.abc`, there is\n`optype.CanIterSelf[V]`, which is a protocol whose `__iter__` returns\n`typing.Self`, as well as a `__next__` method that returns `T`.\nI.e. it is equivalent to `collections.abc.Iterator[V]`, but without the `abc`\nnonsense.\n\nAwaitables\n\nThe `optype.CanAwait[R]` is almost the same as `collections.abc.Awaitable[R]`, except\nthat `optype.CanAwait[R]` is a pure interface, whereas `Awaitable` is\nalso an abstract base class (making it absolutely useless when writing stubs).\n\nAsync Iteration\n\nYes, you guessed it right; the abracadabra collections made the exact same\nmistakes for the async iterablors (or was it \"iteramblers\"...?).\n\nBut fret not; the `optype` alternatives are right here:",
      "word_count": 471
    },
    {
      "chunk_id": "optype::chunk_4",
      "text": "But wait, shouldn't `V` be a `CanAwait`? Well, only if you don't want to get\nfired...\nTechnically speaking, `__anext__` can return any type, and `anext` will pass\nit along without nagging. For details, see the discussion at [python/typeshed#7491][AN].\nJust because something is legal, doesn't mean it's a good idea (don't eat the\nyellow snow).\n\nAdditionally, there is `optype.CanAIterSelf[R]`, with both the\n`__aiter__() -> Self` and the `__anext__() -> V` methods.\n\nContainers\n\nBecause `CanMissing[K, D]` generally doesn't show itself without\n`CanGetitem[K, V]` there to hold its hand, `optype` conveniently stitched them\ntogether as `optype.CanGetMissing[K, V, D=V]`.\n\nSimilarly, there is `optype.CanSequence[K: CanIndex | slice, V]`, which is the\ncombination of both `CanLen` and `CanItem[I, V]`, and serves as a more\nspecific and flexible `collections.abc.Sequence[V]`.\n\nAttributes\n\nContext managers\n\nSupport for the `with` statement.\n\n`CanEnterSelf` and `CanWithSelf` are (runtime-checkable) aliases for\n`CanEnter[Self]` and `CanWith[Self, R]`, respectively.\n\nFor the `async with` statement the interfaces look very similar:\n\nDescriptors\n\nInterfaces for [descriptors](https://docs.python.org/3/howto/descriptor.html).\n\nBuffer types\n\nInterfaces for emulating buffer types using the [buffer protocol][BP].\n\n`optype.copy`\n\nFor the [`copy`][CP] standard library, `optype.copy` provides the following\nruntime-checkable interfaces:\n\n[1] *`copy.replace` requires `python>=3.13`\n(but `optype.copy.CanReplace` doesn't)*\n\nIn practice, it makes sense that a copy of an instance is the same type as the\noriginal.\nBut because `typing.Self` cannot be used as a type argument, this difficult\nto properly type.\nInstead, you can use the `optype.copy.Can{}Self` types, which are the\nruntime-checkable equivalents of the following (non-expressible) aliases:\n\n`optype.dataclasses`\n\nFor the [`dataclasses`][DC] standard library, `optype.dataclasses` provides the\n`HasDataclassFields[V: Mapping[str, Field]]` interface.\nIt can conveniently be used to check whether a type or instance is a\ndataclass, i.e. `isinstance(obj, HasDataclassFields)`.\n\n`optype.inspect`\n\nA collection of functions for runtime inspection of types, modules, and other\nobjects.\n\nA better alternative to [`typing.get_args()`][GET_ARGS], that\n\n- unpacks `typing.Annotated` and Python 3.12 `type _` alias types\n  (i.e. `typing.TypeAliasType`),\n- recursively flattens unions and nested `typing.Literal` types, and\n- raises `TypeError` if not a type expression.\n\nReturn a `tuple[type | object, ...]` of type arguments or parameters.\n\nTo illustrate one of the (many) issues with `typing.get_args`:\n\nBut this is in direct contradiction with the\n[official typing documentation][LITERAL-DOCS]:\n\n> When a Literal is parameterized with more than one value, itâ€™s treated as\n> exactly equivalent to the union of those types.\n> That is, `Literal[v1, v2, v3]` is equivalent to\n> `Literal[v1] | Literal[v2] | Literal[v3]`.\n\nSo this is why `optype.inspect.get_args` should be used\n\nAnother issue of `typing.get_args` is with Python 3.12 `type _ = ...` aliases,\nwhich are meant as a replacement for `_: typing.TypeAlias = ...`, and should\ntherefore be treated equally:\n\nClearly, `typing.get_args` fails miserably here; it would have been better\nif it would have raised an error, but it instead returns an empty tuple,\nhiding the fact that it doesn't support the new `type _ = ...` aliases.\nBut luckily, `optype.inspect.get_args` doesn't have this problem, and treats\nit just like it treats `typing.Alias` (and so do the other `optype.inspect`\nfunctions).\n\nA better alternative to [`typing.get_protocol_members()`][PROTO_MEM], that",
      "word_count": 489
    },
    {
      "chunk_id": "optype::chunk_5",
      "text": "- doesn't require Python 3.13 or above,\n- supports [PEP 695][PEP695] `type _` alias types on Python 3.12 and above,\n- unpacks unions of `typing.Literal` ...\n- ... and flattens them if nested within another `typing.Literal`,\n- treats `typing.Annotated[T]` as `T`, and\n- raises a `TypeError` if the passed value isn't a type expression.\n\nReturns a `frozenset[str]` with member names.\n\nReturns a `frozenset[type]` of the public protocols within the passed module.\nPass `private=True` to also return the private protocols.\n\nCheck whether the object can be iterated over, i.e. if it can be used in a\n`for` loop, without attempting to do so.\nIf `True` is returned, then the object is a `optype.typing.AnyIterable`\ninstance.\n\nCheck if the type, method / classmethod / staticmethod / property, is\ndecorated with [`@typing.final`][@FINAL].\n\nNote that a `@property` won't be recognized unless the `@final` decorator is\nplaced *below* the `@property` decorator.\nSee the function docstring for more information.\n\nA backport of [`typing.is_protocol`][IS_PROTO] that was added in Python 3.13,\na re-export of [`typing_extensions.is_protocol`][IS_PROTO_EXT].\n\nCheck if the type expression is a *runtime-protocol*, i.e. a\n`typing.Protocol` *type*, decorated with `@typing.runtime_checkable` (also\nsupports `typing_extensions`).\n\nCheck if the type is a [`typing.Union`][UNION] type, e.g. `str | int`.\n\nUnlike `isinstance(_, types.Union)`, this function also returns `True` for\nunions of user-defined `Generic` or `Protocol` types (because those are\ndifferent union types for some reason).\n\nCheck if the type is a *subscripted* type, e.g. `list[str]` or\n`optype.CanNext[int]`, but not `list`, `CanNext`.\n\nUnlike `isinstance(_, typing.GenericAlias)`, this function also returns `True`\nfor user-defined `Generic` or `Protocol` types (because those are\nuse a different generic alias for some reason).\n\nEven though technically `T1 | T2` is represented as `typing.Union[T1, T2]`\n(which is a (special) generic alias), `is_generic_alias` will returns `False`\nfor such union types, because calling `T1 | T2` a subscripted type just\ndoesn't make much sense.\n\n> [!NOTE]\n> All functions in `optype.inspect` also work for Python 3.12 `type _` aliases\n> (i.e. `types.TypeAliasType`) and with `typing.Annotated`.\n\n`optype.io`\n\nA collection of protocols and type-aliases that, unlike their analogues in `_typeshed`,\nare accessible at runtime, and use a consistent naming scheme.\n\n`optype.json`\n\nType aliases for the `json` standard library:\n\nThe `(Any)Value` can be any json input, i.e. `Value | Array | Object` is\nequivalent to `Value`.\nIt's also worth noting that `Value` is a subtype of `AnyValue`, which means\nthat `AnyValue | Value` is equivalent to `AnyValue`.\n\n`optype.pickle`\n\nFor the [`pickle`][PK] standard library, `optype.pickle` provides the following\ninterfaces:\n\n`optype.string`\n\nThe [`string`](https://docs.python.org/3/library/string.html) standard\nlibrary contains practical constants, but it has two issues:\n\n- The constants contain a collection of characters, but are represented as\n  a single string. This makes it practically impossible to type-hint the\n  individual characters, so typeshed currently types these constants as a\n  `LiteralString`.\n- The names of the constants are inconsistent, and doesn't follow\n  [PEP 8](https://peps.python.org/pep-0008/#constants).\n\nSo instead, `optype.string` provides an alternative interface, that is\ncompatible with `string`, but with slight differences:",
      "word_count": 477
    },
    {
      "chunk_id": "optype::chunk_6",
      "text": "- For each constant, there is a corresponding `Literal` type alias for\n  the *individual* characters. Its name matches the name of the constant,\n  but is singular instead of plural.\n- Instead of a single string, `optype.string` uses a `tuple` of characters,\n  so that each character has its own `typing.Literal` annotation.\n  Note that this is only tested with (based)pyright / pylance, so it might\n  not work with mypy (it has more bugs than it has lines of codes).\n- The names of the constant are consistent with PEP 8, and use a postfix\n  notation for variants, e.g. `DIGITS_HEX` instead of `hexdigits`.\n- Unlike `string`, `optype.string` has a constant (and type alias) for\n  binary digits `'0'` and `'1'`; `DIGITS_BIN` (and `DigitBin`). Because\n  besides `oct` and `hex` functions in `builtins`, there's also the\n  `builtins.bin` function.\n\nEach of the `optype.string` constants is exactly the same as the corresponding\n`string` constant (after concatenation / splitting), e.g.\n\nSimilarly, the values within a constant's `Literal` type exactly match the\nvalues of its constant:\n\nThe `optype.inspect.get_args` is a non-broken variant of `typing.get_args`\nthat correctly flattens nested literals, type-unions, and PEP 695 type aliases,\nso that it matches the official typing specs.\n*In other words; `typing.get_args` is yet another fundamentally broken\npython-typing feature that's useless in the situations where you need it\nmost.*\n\n`optype.typing`\n\n`Any*` type aliases\n\nType aliases for anything that can *always* be passed to\n`int`, `float`, `complex`, `iter`, or `typing.Literal`\n\n> [!NOTE]\n> Even though *some* `str` and `bytes` can be converted to `int`, `float`,\n> `complex`, most of them can't, and are therefore not included in these\n> type aliases.\n\n`Empty*` type aliases\n\nThese are builtin types or collections that are empty, i.e. have length 0 or\nyield no elements.\n\nLiteral types\n\n`optype.dlpack`\n\nA collection of low-level types for working [DLPack](DOC-DLPACK).\n\nProtocols\n\nThe `+` prefix indicates that the type parameter is *co*variant.\n\nEnums\n\nThere are also two convenient\n[`IntEnum`](https://docs.python.org/3/library/enum.html#enum.IntEnum)s\nin `optype.dlpack`: `DLDeviceType` for the device types, and `DLDataTypeCode` for the\ninternal type-codes of the `DLPack` data types.\n\n`optype.numpy`\n\nOptype supports both NumPy 1 and 2. The current minimum supported version is `1.25`,\nfollowing [NEP 29][NEP29] and [SPEC 0][SPEC0].\n\n`optype.numpy` uses [`numpy-typing-compat`][NPTC] package to ensure compatibility for\nolder versions of NumPy. To ensure that the correct versions of `numpy` and\n`numpy-typing-compat` are installed, you should install `optype` with the `numpy` extra:\n\nIf you're using `conda`, the [`optype-numpy`][CONDA-NP] package can be used, which\nwill also install the required `numpy` and `numpy-typing-compat` versions:\n\n> [!NOTE]\n> For the remainder of the `optype.numpy` docs, assume that the following\n> import aliases are available.\n>\n> \n>\n> For the sake of brevity and readability, the [PEP 695][PEP695] and\n> [PEP 696][PEP696] type parameter syntax will be used, which is supported\n> since Python 3.13.\n\nShape-typing\n\nArray aliases\n\nOptype provides the generic `onp.Array` type alias for `np.ndarray`.\nIt is similar to `npt.NDArray`, but includes two (optional) type parameters:\none that matches the *shape type* (`ND: tuple[int, ...]`),\nand one that matches the *scalar type* (`ST: np.generic`).",
      "word_count": 496
    },
    {
      "chunk_id": "optype::chunk_7",
      "text": "When we put the definitions of `npt.NDArray` and `onp.Array` side-by-side,\ntheir differences become clear:\n\n`numpy.typing.NDArray`[^1]\n\n`optype.numpy.Array`\n\n`optype.numpy.ArrayND`\n\nAdditionally, there are the four `Array{0,1,2,3}D` aliases, which are\nequivalent to `Array` with `tuple[()]`, `tuple[int]`, `tuple[int, int]` and\n`tuple[int, int, int]` as shape-type, respectively.\n\n[^1]: Since `numpy>=2.2` the `NDArray` alias uses `tuple[int, ...]` as shape-type\n\n> [!TIP]\n> Before NumPy 2.1, the shape type parameter of `ndarray` (i.e. the type of\n> `ndarray.shape`) was invariant. It is therefore recommended to not use `Literal`\n> within shape types on `numpy=2.1` you can use\n> `tuple[Literal[3], Literal[3]]` without problem, but with `numpy `tuple[int, int]` instead.\n>\n> See [numpy/numpy#25729](https://github.com/numpy/numpy/issues/25729) and\n> [numpy/numpy#26081](https://github.com/numpy/numpy/pull/26081) for details.\n\nIn the same way as `ArrayND` for `ndarray` (shown for reference), its subtypes\n`np.ma.MaskedArray` and `np.matrix` are also aliased:\n\n`ArrayND` (`np.ndarray`)\n\n`MArray` (`np.ma.MaskedArray`)\n\n`Matrix` (`np.matrix`)\n\nFor masked arrays with specific `ndim`, you could also use one of the four\n`MArray{0,1,2,3}D` aliases.\n\nArray typeguards\n\nTo check whether a given object is an instance of `Array{0,1,2,3,N}D`, in a way that\nstatic type-checkers also understand it, the following [PEP 742][PEP742] typeguards can\nbe used:\n\nThese functions additionally accept an optional `dtype` argument, that can either be\na `np.dtype[ST]` instance, a `type[ST]`, or something that has a `dtype: np.dtype[ST]`\nattribute.\nThe signatures are almost identical to each other, and in the `0d` case it roughly\nlooks like this:\n\nShape aliases\n\nA *shape* is nothing more than a tuple of (non-negative) integers, i.e.\nan instance of `tuple[int, ...]` such as `(42,)`, `(480, 720, 3)` or `()`.\nThe length of a shape is often referred to as the *number of dimensions*\nor the *dimensionality* of the array or scalar.\nFor arrays this is accessible through the `np.ndarray.ndim`, which is\nan alias for `len(np.ndarray.shape)`.\n\n> [!NOTE]\n> Before NumPy 2, the maximum number of dimensions was `32`, but has since\n> been increased to `ndim = N`\n- `AtMost{N}D` is a `tuple[int, ...]` with `ndim\n\n0\n\n1\n\n2\n\n3\n\nThe `AtLeast{}D` optionally accepts a type argument that can either be `int` (default),\nor `Any`. Passing `Any` turns it from a *gradual tuple type*, so that they can also be\nassigned to compatible bounded shape-types. So `AtLeast1D[Any]` is assignable to\n`tuple[int]`, whereas `AtLeast1D` (equiv. `AtLeast1D[int]`) is not.\n\nHowever, mypy currently has a [bug](https://github.com/python/mypy/issues/19109),\ncausing it to falsely reject such gradual shape-type assignment for N=1 or up.\n\nArray-likes\n\nSimilar to the `numpy._typing._ArrayLike{}_co` *coercible array-like* types,\n`optype.numpy` provides the `optype.numpy.To{}ND`. Unlike the ones in `numpy`, these\ndon't accept \"bare\" scalar types (the `__len__` method is required).\nAdditionally, there are the `To{}1D`, `To{}2D`, and `To{}3D` for vector-likes,\nmatrix-likes, and cuboid-likes, and the `To{}` aliases for \"bare\" scalar types.\n\n> [!NOTE]\n> The `To*Strict{1,2,3}D` aliases were added in `optype 0.7.3`.\n>\n> These array-likes with *strict shape-type* require the shape-typed input to be\n> shape-typed.\n> This means that e.g. `ToFloat1D` and `ToFloat2D` are disjoint (non-overlapping),\n> and makes them suitable to overload array-likes of a particular dtype for different\n> numbers of dimensions.",
      "word_count": 491
    },
    {
      "chunk_id": "optype::chunk_8",
      "text": "> [!NOTE]\n> The `ToJust{Bool,Float,Complex}*` type aliases were added in `optype 0.8.0`.\n>\n> See [`optype.Just`](#just) for more information.\n\n> [!NOTE]\n> The `To[Just]{False,True}` type aliases were added in `optype 0.9.1`.\n>\n> These only include the `np.bool` types on `numpy>=2.2`. Before that, `np.bool`\n> wasn't generic, making it impossible to distinguish between `np.False_` and `np.True_`\n> using static typing.\n\n> [!NOTE]\n> The `ToArrayStrict{1,2,3}D` types are generic since `optype 0.9.1`, analogous to\n> their non-strict dual type, `ToArray{1,2,3}D`.\n\n> [!NOTE]\n> The `To[Just]{Float16,Float32,Complex64}*` type aliases were added in `optype 0.12.0`.\n\nSource code: [`optype/numpy/_to.py`][CODE-NP-TO]\n\nLiterals\n\nType Alias\n---------------\n`ByteOrder`\n`ByteOrderChar`\n`ByteOrderName`\n`Casting`\n`CastingUnsafe`\n`CastingSafe`\n`ConvolveMode`\n`Device`\n`IndexMode`\n`OrderCF`\n`OrderACF`\n`OrderKACF`\n`PartitionKind`\n`SortKind`\n`SortSide`\n\n`compat` submodule\n\nCompatibility module for supporting a wide range of numpy versions (currently `>=1.25`).\nIt contains the abstract numeric scalar types, with `numpy>=2.2`\ntype-parameter defaults, which I explained in the [`release notes`][NP-REL22].\n\n`random` submodule\n\n[SPEC 7](https://scientific-python.org/specs/spec-0007/) -compatible type aliases.\nThe `optype.numpy.random` module provides three type aliases: `RNG`, `ToRNG`, and\n`ToSeed`.\n\nIn general, the most useful one is `ToRNG`, which describes what can be\npassed to `numpy.random.default_rng`. It is defined as the union of `RNG`, `ToSeed`,\nand `numpy.random.BitGenerator`.\n\nThe `RNG` is the union type of `numpy.random.Generator` and its legacy dual type,\n`numpy.random.RandomState`.\n\n`ToSeed` accepts integer-like scalars, sequences, and arrays, as well as instances of\n`numpy.random.SeedSequence`.\n\n`DType`\n\nIn NumPy, a *dtype* (data type) object, is an instance of the\n`numpy.dtype[ST: np.generic]` type.\nIt's commonly used to convey metadata of a scalar type, e.g. within arrays.\n\nBecause the type parameter of `np.dtype` isn't optional, it could be more\nconvenient to use the alias `optype.numpy.DType`, which is defined as:\n\nApart from the \"CamelCase\" name, the only difference with `np.dtype` is that\nthe type parameter can be omitted, in which case it's equivalent to\n`np.dtype[np.generic]`, but shorter.\n\n`Scalar`\n\nThe `optype.numpy.Scalar` interface is a generic runtime-checkable protocol,\nthat can be seen as a \"more specific\" `np.generic`, both in name, and from\na typing perspective.\n\nIts type signature looks roughly like this:\n\nIt can be used as e.g.\n\n> [!NOTE]\n> The second type argument for `itemsize` can be omitted, which is equivalent\n> to setting it to `int`, so `Scalar[PT]` and `Scalar[PT, int]` are equivalent.\n\n`UFunc`\n\nA large portion of numpy's public API consists of *universal functions*, often\ndenoted as [ufuncs][DOC-UFUNC], which are (callable) instances of\n[`np.ufunc`][REF_UFUNC].\n\n> [!TIP]\n> Custom ufuncs can be created using [`np.frompyfunc`][REF_FROMPY], but also\n> through a user-defined class that implements the required attributes and\n> methods (i.e., duck typing).\n\nBut `np.ufunc` has a big issue; it accepts no type parameters.\nThis makes it very difficult to properly annotate its callable signature and\nits literal attributes (e.g. `.nin` and `.identity`).\n\nThis is where `optype.numpy.UFunc` comes into play:\nIt's a runtime-checkable generic typing protocol, that has been thoroughly\ntype- and unit-tested to ensure compatibility with all of numpy's ufunc\ndefinitions.\nIts generic type signature looks roughly like:",
      "word_count": 478
    },
    {
      "chunk_id": "optype::chunk_9",
      "text": "> [!NOTE]\n> Unfortunately, the extra callable methods of `np.ufunc` (`at`, `reduce`,\n> `reduceat`, `accumulate`, and `outer`), are incorrectly annotated (as `None`\n> *attributes*, even though at runtime they're methods that raise a\n> `ValueError` when called).\n> This currently makes it impossible to properly type these in\n> `optype.numpy.UFunc`; doing so would make it incompatible with numpy's\n> ufuncs.\n\n`Any*Array` and `Any*DType`\n\nThe `Any{Scalar}Array` type aliases describe array-likes that are coercible to an\n`numpy.ndarray` with specific [dtype][REF-DTYPES].\n\nUnlike `numpy.typing.ArrayLike`, these `optype.numpy` aliases **don't**\naccept \"bare\" scalar types such as `float` and `np.float64`. However, arrays of\n\"zero dimensions\" like `onp.Array[tuple[()], np.float64]` will be accepted.\nThis is in line with the behavior of [`numpy.isscalar`][REF-ISSCALAR] on `numpy >= 2`.\n\n> [!NOTE]\n> The [`numpy.dtypes` docs][REF-DTYPES] exists since NumPy 1.25, but its\n> type annotations were incorrect before NumPy 2.1 (see\n> [numpy/numpy#27008](https://github.com/numpy/numpy/pull/27008))\n\nSee the [docs][REF-SCT] for more info on the NumPy scalar type hierarchy.\n\nAbstract types\n\nUnsigned integers\n\n`uint_`[^5]\n\n`uint32`[^6]\n\n`uintc`[^6]\n\n`ulong`[^7]\n\nSigned integers\n\n`int_`[^5]\n\n`int32`[^6]\n\n`intc`[^6]\n\n`long`[^7]\n\n[^5]: Since NumPy 2, `np.uint` and `np.int_` are aliases for `np.uintp` and `np.intp`, respectively.\n\n[^6]: On unix-based platforms `np.[u]intc` are aliases for `np.[u]int32`.\n\n[^7]: On NumPy 1 `np.uint` and `np.int_` are what in NumPy 2 are now the `np.ulong` and `np.long` types, respectively.\n\nReal floats\n\n`longdouble`[^13]\n\n[^13]: Depending on the platform, `np.longdouble` is (almost always) an alias for **either** `float128`,\n\nComplex floats\n\n`clongdouble`[^16]\n\n[^16]: Depending on the platform, `np.clongdouble` is (almost always) an alias for **either** `complex256`,\n\n\"Flexible\"\n\nScalar types with \"flexible\" length, whose values have a (constant) length\nthat depends on the specific `np.dtype` instantiation.\n\nOther types\n\n`bool_`[^0]\n\n*`generic`*[^22]\n\n[^2056]\n\n[^0]: Since NumPy 2, `np.bool` is preferred over `np.bool_`, which only exists for backwards compatibility.\n\n[^22]: At runtime `np.timedelta64` is a subclass of `np.signedinteger`, but this is currently not\n\n[^2056]: The `np.dypes.StringDType` has no associated numpy scalar type, and its `.type` attribute returns the\n\nLow-level interfaces\n\nWithin `optype.numpy` there are several `Can*` (single-method) and `Has*`\n(single-attribute) protocols, related to the `__array_*__` dunders of the\nNumPy Python API.\nThese typing protocols are, just like the `optype.Can*` and `optype.Has*` ones,\nruntime-checkable and extensible (i.e. not `@final`).\n\n> [!TIP]\n> All type parameters of these protocols can be omitted, which is equivalent\n> to passing its upper type bound.\n\n[User Guide: Interoperability with NumPy][DOC-ARRAY]\n\n[NEP 13][NEP13]\n\n[NEP 18][NEP18]\n\n[User Guide: Subclassing ndarray][DOC-AFIN]\n\n[API: Standard array subclasses][REF_ARRAY-WRAP]\n\n[API: The array interface protocol][REF_ARRAY-INTER]\n\n[API: Standard array subclasses][REF_ARRAY-PRIO]\n\n[API: Specifying and constructing data types][REF_DTYPE]",
      "word_count": 405
    }
  ]
}